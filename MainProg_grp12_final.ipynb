{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402d0748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pin-code.org.in/pincode/224207 : Processing\n",
      "https://pin-code.org.in/pincode/244715 : Processing\n",
      "https://pin-code.org.in/pincode/246700 : Processing\n",
      "https://pin-code.org.in/pincode/271904 : Processing\n",
      "https://pin-code.org.in/pincode/272206 : Processing\n",
      "https://pin-code.org.in/pincode/281406 : Processing\n",
      "https://pin-code.org.in/pincode/284135 : Processing\n",
      "https://pin-code.org.in/pincode/303503 : Processing\n",
      "https://pin-code.org.in/pincode/305009 : Processing\n",
      "https://pin-code.org.in/pincode/305601 : Processing\n",
      "https://pin-code.org.in/pincode/305624 : Processing\n",
      "https://pin-code.org.in/pincode/306305 : Processing\n",
      "https://pin-code.org.in/pincode/313015 : Processing\n",
      "https://pin-code.org.in/pincode/333042 : Processing\n",
      "https://pin-code.org.in/pincode/341012 : Processing\n",
      "https://pin-code.org.in/pincode/363250 : Processing\n",
      "https://pin-code.org.in/pincode/364070 : Processing\n",
      "https://pin-code.org.in/pincode/380045 : Processing\n",
      "https://pin-code.org.in/pincode/380052 : Processing\n",
      "https://pin-code.org.in/pincode/382002 : Processing\n",
      "https://pin-code.org.in/pincode/382009 : Processing\n",
      "https://pin-code.org.in/pincode/382013 : Processing\n",
      "https://pin-code.org.in/pincode/382115 : Processing\n",
      "https://pin-code.org.in/pincode/382346 : Processing\n",
      "https://pin-code.org.in/pincode/382428 : Processing\n",
      "https://pin-code.org.in/pincode/384325 : Processing\n",
      "https://pin-code.org.in/pincode/385120 : Processing\n",
      "https://pin-code.org.in/pincode/388120 : Processing\n",
      "https://pin-code.org.in/pincode/388560 : Processing\n",
      "https://pin-code.org.in/pincode/388570 : Processing\n",
      "https://pin-code.org.in/pincode/389351 : Processing\n",
      "https://pin-code.org.in/pincode/389352 : Processing\n",
      "https://pin-code.org.in/pincode/390002 : Processing\n",
      "https://pin-code.org.in/pincode/391168 : Processing\n",
      "https://pin-code.org.in/pincode/394602 : Processing\n",
      "https://pin-code.org.in/pincode/401206 : Processing\n",
      "https://pin-code.org.in/pincode/403202 : Processing\n",
      "https://pin-code.org.in/pincode/410217 : Processing\n",
      "https://pin-code.org.in/pincode/414207 : Processing\n",
      "https://pin-code.org.in/pincode/431719 : Processing\n",
      "https://pin-code.org.in/pincode/470663 : Processing\n",
      "https://pin-code.org.in/pincode/504204 : Processing\n",
      "https://pin-code.org.in/pincode/509126 : Processing\n",
      "https://pin-code.org.in/pincode/515601 : Processing\n",
      "https://pin-code.org.in/pincode/533271 : Processing\n",
      "https://pin-code.org.in/pincode/533305 : Processing\n",
      "https://pin-code.org.in/pincode/533431 : Processing\n",
      "https://pin-code.org.in/pincode/533464 : Processing\n",
      "https://pin-code.org.in/pincode/534271 : Processing\n",
      "https://pin-code.org.in/pincode/560018 : Processing\n",
      "https://pin-code.org.in/pincode/560072 : Processing\n",
      "https://pin-code.org.in/pincode/560077 : Processing\n",
      "https://pin-code.org.in/pincode/574286 : Processing\n",
      "https://pin-code.org.in/pincode/576255 : Processing\n",
      "https://pin-code.org.in/pincode/585263 : Processing\n",
      "https://pin-code.org.in/pincode/586113 : Processing\n",
      "https://pin-code.org.in/pincode/586243 : Processing\n",
      "https://pin-code.org.in/pincode/623702 : Processing\n",
      "https://pin-code.org.in/pincode/625120 : Processing\n",
      "https://pin-code.org.in/pincode/627252 : Processing\n",
      "https://pin-code.org.in/pincode/627752 : Processing\n",
      "https://pin-code.org.in/pincode/636008 : Processing\n",
      "https://pin-code.org.in/pincode/685509 : Processing\n",
      "https://pin-code.org.in/pincode/686568 : Processing\n",
      "https://pin-code.org.in/pincode/711414 : Processing\n",
      "https://pin-code.org.in/pincode/743515 : Processing\n",
      "https://pin-code.org.in/pincode/127114 : Processing\n",
      "https://pin-code.org.in/pincode/134008 : Processing\n",
      "https://pin-code.org.in/pincode/144027 : Processing\n",
      "https://pin-code.org.in/pincode/144502 : Processing\n",
      "https://pin-code.org.in/pincode/148051 : Processing\n",
      "https://pin-code.org.in/pincode/160010 : Processing\n",
      "https://pin-code.org.in/pincode/190012 : Processing\n",
      "https://pin-code.org.in/pincode/203551 : Processing\n",
      "https://pin-code.org.in/pincode/221307 : Processing\n",
      "https://pin-code.org.in/pincode/223107 : Processing\n",
      "https://pin-code.org.in/pincode/224175 : Processing\n",
      "https://pin-code.org.in/pincode/230130 : Processing\n",
      "https://pin-code.org.in/pincode/230502 : Processing\n",
      "https://pin-code.org.in/pincode/245201 : Processing\n",
      "https://pin-code.org.in/pincode/248145 : Processing\n",
      "https://pin-code.org.in/pincode/262122 : Processing\n",
      "https://pin-code.org.in/pincode/271803 : Processing\n",
      "https://pin-code.org.in/pincode/272209 : Processing\n",
      "https://pin-code.org.in/pincode/273211 : Processing\n",
      "https://pin-code.org.in/pincode/273307 : Processing\n",
      "https://pin-code.org.in/pincode/301043 : Processing\n",
      "https://pin-code.org.in/pincode/303120 : Processing\n",
      "https://pin-code.org.in/pincode/307710 : Processing\n",
      "https://pin-code.org.in/pincode/313613 : Processing\n",
      "https://pin-code.org.in/pincode/313805 : Processing\n",
      "https://pin-code.org.in/pincode/322211 : Processing\n",
      "https://pin-code.org.in/pincode/322245 : Processing\n",
      "https://pin-code.org.in/pincode/325201 : Processing\n",
      "https://pin-code.org.in/pincode/327034 : Processing\n",
      "https://pin-code.org.in/pincode/328024 : Processing\n",
      "https://pin-code.org.in/pincode/360585 : Processing\n",
      "https://pin-code.org.in/pincode/363416 : Processing\n",
      "https://pin-code.org.in/pincode/382724 : Processing\n",
      "https://pin-code.org.in/pincode/387120 : Processing\n",
      "https://pin-code.org.in/pincode/387435 : Processing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen \n",
    "import json\n",
    "import numpy\n",
    "import requests\n",
    "import re\n",
    "\n",
    "####################### Define Variables and Functions ########################################\n",
    "\n",
    "view_url = \"https://pin-code.org.in\" \n",
    "comp_url = \"companies/viewall/\"\n",
    "bank_url = \"banks/viewall/\"\n",
    "hosp_url = \"Hospitals/viewall/\"\n",
    "crawl_url = ''\n",
    "\n",
    "def mainfun(url,pin_loop,outdf):\n",
    "    bank = []\n",
    "    ngo = []\n",
    "    hospital = []\n",
    "    row_final =[]\n",
    "    titlehref = []\n",
    "    hosp_urls = []\n",
    "    bank_urls = []\n",
    "    comp_cnt = 0\n",
    "    bank_cnt = 0\n",
    "    ngo_cnt = 0\n",
    "    hosp_cnt = 0\n",
    "    hosp_pvt_cnt = 0\n",
    "    hosp_pub_cnt = 0\n",
    "    str_cnt =0 \n",
    "    url_list_visited = []\n",
    "    url_list_final = []\n",
    "    \n",
    "    \n",
    "######################## Start : this function is to Crawl the pages ##########################################\n",
    "    def crawl_fun(crawl_url,url_list_final):\n",
    "        url_list_temp = []\n",
    "\n",
    "        res = requests.get(crawl_url).content\n",
    "        soup = BeautifulSoup(res,'html.parser')\n",
    "        url_class = soup.find_all(\"ul\", {\"class\" : \"pagination pt-3 pt-md-0\"})\n",
    "        for i in url_class:\n",
    "            b = i.select(\"a\",href = True)\n",
    "            for c in b:\n",
    "                url_list_temp.append(view_url+c.get('href'))\n",
    "\n",
    "        for temp_url in url_list_temp:\n",
    "            if temp_url not in url_list_final:\n",
    "                url_list_final.append(temp_url)\n",
    "        return()  \n",
    "\n",
    "    def crawl_visited(crawl_url,url_list_visited,url_list_final):\n",
    "        while len(url_list_visited) < len(url_list_final) or (len(url_list_visited) < 10) :\n",
    "            for cur_url in url_list_final:\n",
    "                crawl_fun(cur_url,url_list_final)\n",
    "                url_list_visited.append(cur_url)\n",
    "            return()\n",
    "\n",
    "######################## End : this function is to Crawl the pages ##########################################\n",
    "\n",
    "######################## Start : this function is split the string and get count #########################################\n",
    "    def str_split(str1):\n",
    "        str_cnt1 = ''\n",
    "        for f1 in str1:\n",
    "            if f1.isdigit():\n",
    "                str_cnt1 = str_cnt1 + f1\n",
    "        str_cnt = int(str_cnt1)\n",
    "        return(str_cnt)\n",
    "\n",
    "######################## End : this function is split the string and get count ##########################################\n",
    "\n",
    "######################## Start - this logic is to scrap and read the summary of counts  #################################\n",
    "\n",
    "    res = requests.get(url).content\n",
    "    soup = BeautifulSoup(res,'html.parser')\n",
    "    \n",
    "    html_sumry = soup.find_all('h5',class_ = 'text-center')\n",
    "    for i in html_sumry:\n",
    "        sumry = i.get_text()\n",
    "        sumry = str(sumry)\n",
    "        str1 = sumry.split(\":\")\n",
    "        str2 = str1[1].split(\",\")\n",
    "        \n",
    "        for j in str2:\n",
    "            if 'Banks' in j:\n",
    "                bank_cnt = str_split(j)\n",
    "            if 'Companies' in j:\n",
    "                comp_cnt = str_split(j)  \n",
    "            #if 'Post Offices' in j:\n",
    "            #    print(\"Postoffice count :\" + str(str_split(j)))\n",
    "            if 'Hospitals' in j:\n",
    "                hosp_cnt = str_split(j)\n",
    "        if bank_cnt < 11:\n",
    "            bank_cnt = 0\n",
    "        #if comp_cnt < 11:\n",
    "        #    comp_cnt = 0\n",
    "        if hosp_cnt < 1:\n",
    "            hosp_cnt = 0      \n",
    "######################## End - this logic is to Scrap and read the summary of counts  ######################################\n",
    "\n",
    "######################## Start - this logic is to Scrap the contents of page  ##########################################\n",
    "           \n",
    "    html_parts = soup.find_all('div', class_= 'col-sm-6 col-12 pr-sm-2')\n",
    "\n",
    "    for i in html_parts:\n",
    "        b = i.select_one(\"a\",href = True)\n",
    "        check_var = b['href']\n",
    "        if (check_var.find('https://pin-code.org.in/banks') == 0 ) and (bank_cnt < 11):\n",
    "            bank.append(str(b.contents[0]))\n",
    "            bank_cnt = bank_cnt + 1\n",
    "        if (check_var.find('https://pin-code.org.in/hospitals') == 0 ) and (hosp_cnt < 1) :\n",
    "            hospital.append(str(b.contents[0]))\n",
    "            hosp_cnt = hosp_cnt + 1\n",
    "        if (check_var.find('https://pin-code.org.in/ngo') == 0 ):\n",
    "            ngo.append(str(b.contents[0]))\n",
    "            ngo_cnt = ngo_cnt + 1\n",
    "            \n",
    "############################ End - this logic is to Scrap the contents of page  ##########################################\n",
    "\n",
    "\n",
    "######################## Start - Use additional crawling if count is greater than 10 ###############################\n",
    "       \n",
    "    if (bank_cnt > 10):\n",
    "        crawl_url = view_url + \"/\"+ bank_url + str(pin_loop)\n",
    "        url_list_visited = []\n",
    "        url_list_final = []\n",
    "        url_list_final.append(crawl_url)\n",
    "        crawl_visited(crawl_url,url_list_visited, url_list_final)\n",
    "        bank_urls = url_list_final\n",
    "        \n",
    "    if (hosp_cnt > 0):\n",
    "        crawl_url = view_url + \"/\"+ hosp_url + str(pin_loop)\n",
    "        url_list_visited = []\n",
    "        url_list_final = []\n",
    "        url_list_final.append(crawl_url)\n",
    "        crawl_visited(crawl_url,url_list_visited, url_list_final)\n",
    "        hosp_urls = url_list_final\n",
    "  \n",
    " ######################## End - Use additional crawling if count is greater than 10 #####################################\n",
    "    \n",
    "    \n",
    "######################## Start - Use additional crawling if count is greater than 10 ###############################    \n",
    "        \n",
    "    if (bank_cnt > 10):\n",
    "        for crw_url in bank_urls: \n",
    "            res = requests.get(crw_url).content\n",
    "            soup = BeautifulSoup(res,'html.parser')\n",
    "            url_class = soup.find_all(\"h3\", {\"class\" : \"panel-title\"})\n",
    "            for i in url_class:\n",
    "                bank.append(str(i.get_text())) \n",
    "                \n",
    "    if (hosp_cnt > 0):\n",
    "        for crw_url in hosp_urls: \n",
    "            res = requests.get(crw_url).content\n",
    "            soup = BeautifulSoup(res,'html.parser')\n",
    "            url_class = soup.find_all(\"div\", {\"class\" : \"companyDetails\"})\n",
    "            for i in url_class:\n",
    "                b = i.select_one(\"a\",href = True)\n",
    "                check_var = b['href']\n",
    "                if (check_var.find('https://pin-code.org.in/hospitals/details/') == 0):\n",
    "                    hospital.append(str(b.contents[0]))\n",
    "                    hosp_cat = i.contents[7].get_text().split(\":\")\n",
    "                    if hosp_cat[1] == 'Private':\n",
    "                        hosp_pvt_cnt = hosp_pvt_cnt + 1\n",
    "                    else:\n",
    "                        hosp_pub_cnt = hosp_pub_cnt + 1\n",
    "                \n",
    "                    \n",
    "                    \n",
    "  \n",
    " ######################## End - Use additional crawling if count is greater than 10 #####################################\n",
    "    \n",
    " ######################## Start - this logic is to build the dataframe from contents collected ###########################\n",
    "    pin_list = [pin_loop]\n",
    "    bank_cnt_list = [bank_cnt]\n",
    "    company_cnt_list = [comp_cnt]\n",
    "    ngo_cnt_list = [ngo_cnt]\n",
    "    hospital_cnt_list = [hosp_cnt]\n",
    "    hosp_pvt_list = [hosp_pvt_cnt]\n",
    "    hosp_pub_list = [hosp_pub_cnt]\n",
    "   \n",
    "   \n",
    "    hospital_list = []\n",
    "    hospital_list.append(hospital[0:])\n",
    "    \n",
    "    ngo_list = []\n",
    "    ngo_list.append(ngo[0:])\n",
    "    \n",
    "    \n",
    "    bank_list = []\n",
    "    bank_list.append(bank[0:])\n",
    "        \n",
    "        \n",
    "    row_final = pin_list + bank_cnt_list + bank_list + company_cnt_list #+ company_list \n",
    "    \n",
    "    row_final = row_final + hospital_cnt_list + hosp_pvt_list + hosp_pub_list + hospital_list +  ngo_cnt_list + ngo_list\n",
    "    \n",
    "    dict1 = zip(varlist,row_final)\n",
    "    dict2 = dict(dict1)\n",
    "    outdf.loc[len(outdf.index)] = row_final\n",
    "    return \n",
    "\n",
    " ######################## End of the logic to build the dataframe from contents collected ###########################\n",
    "  \n",
    "\n",
    " ######################## Main Program to loop each pincode from excel  ###########################\n",
    "#main program\n",
    "fix_url = \"https://pin-code.org.in/pincode/\"\n",
    "data = pd.read_excel('C:/Users/Admin/Desktop/ISB/Term1/DC/assignment/Indian_Pincodes.xlsx')\n",
    "postlist = (data['pin_code'])\n",
    "#postlist = [500001]\n",
    "#outdf = pd.DataFrame()\n",
    "varlist = ['Postal Code','Bank_Count','BankNames','Company_Count']\n",
    "#varlist.append('CompanyNames')\n",
    "varlist.append('Hospital_Count')\n",
    "varlist.append('PvtHospital_Count')\n",
    "varlist.append('GovtHospital_Count')\n",
    "varlist.append('HospitalNames')\n",
    "varlist.append('NGO_Count')\n",
    "varlist.append('NGONames')\n",
    "outdf = pd.DataFrame(columns =varlist)\n",
    "#print(outdf)\n",
    "limit = 0\n",
    "pinloop = 0\n",
    "for pin_loop in postlist:\n",
    "    url = fix_url + str(pin_loop)\n",
    "    print(url + \" : Processing\")\n",
    "    limit = limit + 1\n",
    "    #### change the value below to limit the loop ####\n",
    "    ##if limit > 100:\n",
    "     ##   break;\n",
    "        \n",
    "    mainfun(url,pin_loop,outdf)\n",
    "    \n",
    "#print(outdf)\n",
    "\n",
    "######################## End of Main Program to loop each pincode from excel  ###########################\n",
    "\n",
    "######################## Logic to write the dataframe to Json file  ###########################\n",
    "\n",
    "#### Uncomment below 2 lines to write to json ############\n",
    "#json_data = outdf.to_json(orient='records')\n",
    "#print(json_data)\n",
    "\n",
    "########################  End of Logic to write the dataframe to Json file  ###########################\n",
    "\n",
    "######################## Logic to write the dataframe to excel  file  ###########################\n",
    "\n",
    "#### Uncomment below 3 lines to write to excel ############\n",
    "writer = pd.ExcelWriter('C:/Users/Admin/Desktop/ISB/Term1/DC/assignment/pincode_out1.xlsx', engine='xlsxwriter')\n",
    "outdf.to_excel(writer,sheet_name = 'Sheet1', index=False)\n",
    "writer.save() \n",
    "#### Uncomment to write to excel ############\n",
    "#####outdf.to_excel('C:/Users/Admin/Desktop/ISB/Term1/DC/assignment/pincode_out.xlsx', header = True)\n",
    "\n",
    "######################## End of Logic to write the dataframe to excel  file  ###########################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
